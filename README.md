# Explainable BERT: A More Interpretable Transformer

This project introduces a custom BERT variant designed to **enhance interpretability** by replacing the final multi-head attention layer with a **Single-Head Self Attention** block.

ğŸ’¡ The goal: sharpen token-level focus and make model decisions more **human-understandable** â€” without increasing parameter count or complexity.

---

![Architecture Diagram](./architecture_diagram.png)

---

## ğŸ“Œ Core Idea

In standard BERT, the final attention layer often spreads focus across many tokens â€” even irrelevant ones.

My approach:
> **Replace the final multi-head attention block** with a **single-head attention layer** to force sharper, more focused token-level decisions.

This results in:
âœ… Simpler computation in final layer  
âœ… Cleaner attention maps  
âœ… Improved test accuracy (+1%)  
âœ… Same parameter count  
âœ… Much better visual and logical explainability

---

## ğŸ§  Attention Visualization

Here are **side-by-side attention map comparisons** between the original BERT and the modified explainable version on three different input examples:

### ğŸ” Example 1
![](./attention_comparison_1.png)

---

### ğŸ” Example 2
![](./attention_comparison_2.png)

---

### ğŸ” Example 3
![](./attention_comparison_3.png)

---

âœ… In each case, youâ€™ll notice that **Explainable BERT sharply locks onto the key token**, while Base BERT often dilutes attention across multiple less relevant words.  
This results in more interpretable outputs, better visual saliency, and cleaner decision traces for human understanding.

---

##  Repo Contents

This repo includes two tracks of development:

###  1. Working Prototype (Jupyter Notebook)
ğŸ“ [`Main_Workflow.ipynb`](./Main_Workflow.ipynb)

- Custom BERT architecture
- Simple training pipeline
- Visual comparison of token attention maps
- Binary sentiment classification (toy dataset)

---

###  2. Scalable Modular Version (In Progress)

Iâ€™m actively building a more scalable, production-ready version using Python modules.


Planned features:
- Full HuggingFace tokenizer integration  
- CLI support for training and inference  
- Visual attention map exports  
- Comparative evaluation vs vanilla BERT

---

### âš¡ Interactive Inference with Gradio (Coming Soon)

Iâ€™m also working on a lightweight **Gradio-based UI** to:
- Run inference on custom input sentences  
- Display attention maps showing key token focus  
- Compare base BERT vs explainable BERT on the fly

This will help users **visually understand how decisions are made**, right in the browser â€” no code required.

---

## ğŸ™Œ About Me

This project was designed and built by [**Kamalesh V**](https://www.linkedin.com/in/kamalesh007/) â€” an engineering student and AI builder working across the stack:  
Deep learning, NLP, CV, Transformers, XAI, and model deployment.

I'm passionate about building **original, useful, and scalable AI systems** â€” from **research-inspired ideas** to **real-world implementation**.

If you're working on machine learning, AI infrastructure, or experimental model design â€” feel free to connect and exchange ideas.




